{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg11ENFWoi6G"
      },
      "source": [
        "<h1><b>Transferencia de estilo con TensorHub</b></h1>\n",
        "\n",
        "<author>Julio Waissman Vilanova</author>\n",
        "\n",
        "<br/>\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/juliowaissman/intro-rn/blob/main/transfer_img.ipynb\">\n",
        "<img src=\"https://i.ibb.co/2P3SLwK/colab.png\" width=30pt />\n",
        "<i>Para usar en Google Colab</i></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRZPmBXSoGww"
      },
      "source": [
        "## Tranferencia de estilo\n",
        "\n",
        "Tomado de [este ejemplo](https://www.tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization) y basado en el código del modelo en [magenta](https://github.com/tensorflow/magenta/tree/master/magenta/models/arbitrary_image_stylization) y la publicación:\n",
        "\n",
        "[Explorar la estructura de un tiempo real, la red arbitraria estilización artística neuronal](https://arxiv.org/abs/1705.06830) . *Golnaz Ghiasi, Honglak Lee, Manjunath Kudlur, Vincent Dumoulin, Jonathon Shlens*, Actas de la Conferencia British Machine Vision (BMVC), 2017.\n",
        "\n",
        "Empecemos importando las librerías que vamos a necesitar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbgMhSkRqwaF"
      },
      "outputs": [],
      "source": [
        "# Para descargar las imagenes de estilo y contenido\n",
        "import functools\n",
        "import os\n",
        "\n",
        "# Para graficar las imágenes\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "# Las que no pueden faltar\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Para obtener los modelos preentrenados\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Vamos viendo un poco de información\n",
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"TF Hub version: \", hub.__version__)\n",
        "print(\"Eager mode enabled: \", tf.executing_eagerly())\n",
        "print(\"GPU available: \", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-uOy1_8rVBW"
      },
      "source": [
        "Vamos primero a definir algunas funciones para descargar las imágenes y para visualizarlas. \n",
        "\n",
        "Es importante aqui hablar sobre decoradores en python, si es que no los conocen. En este caso el decorador (de las herramientas de programación funcional de python) es para agregar **memoización** a la función. Esto es, que si la función ya se ejecuto una vez con esas entradas, guadre la salida en una memoria cache, para no tener que recalcularlo cada vez.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nql0kPHwrUY3"
      },
      "outputs": [],
      "source": [
        "def crop_center(image):\n",
        "  \"\"\"\n",
        "  Recibe una imagen de (3, n, m) y regresa\n",
        "  una imagen cuadrada de (3, min(n,m), min(n,m))\n",
        "  centrada\n",
        "  \n",
        "  \"\"\"\n",
        "  shape = image.shape\n",
        "  new_shape = min(shape[1], shape[2])\n",
        "  offset_y = max(shape[1] - shape[2], 0) // 2\n",
        "  offset_x = max(shape[2] - shape[1], 0) // 2\n",
        "  \n",
        "  image = tf.image.crop_to_bounding_box(\n",
        "      image, offset_y, offset_x, new_shape, new_shape\n",
        "  )\n",
        "  \n",
        "  return image\n",
        "\n",
        "def show_n(images, titles=('',)):\n",
        "  \"\"\"\n",
        "  Muestra una serie de imagenes en forma horizontal\n",
        "  y les agrega los títulos correspondientes\n",
        "\n",
        "  \"\"\"\n",
        "  n = len(images)\n",
        "  image_sizes = [image.shape[1] for image in images]\n",
        "  w = (image_sizes[0] * 6) // 320\n",
        "  plt.figure(figsize=(w * n, w))\n",
        "  gs = gridspec.GridSpec(1, n, width_ratios=image_sizes)\n",
        "  for i in range(n):\n",
        "    plt.subplot(gs[i])\n",
        "    plt.imshow(images[i][0], aspect='equal')\n",
        "    plt.axis('off')\n",
        "    plt.title(titles[i] if len(titles) > i else '')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "@functools.lru_cache(maxsize=None)\n",
        "def load_image(image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n",
        "  \"\"\"\n",
        "  Carga y procesa una imagen. \n",
        "\n",
        "  Usa memoización (@functools.lru_cache) para no descargar la misma imagen muchas veces\n",
        "  \n",
        "  \"\"\"\n",
        "  # Descarga el archivo de la imagen en crudo\n",
        "  image_path = tf.keras.utils.get_file(\n",
        "      os.path.basename(image_url)[-128:], image_url\n",
        "  )\n",
        "\n",
        "  # Carga y procesa la imagen\n",
        "  img = tf.io.decode_image(\n",
        "      tf.io.read_file(image_path),\n",
        "      channels=3, dtype=tf.float32\n",
        "  )[tf.newaxis, ...] \n",
        "\n",
        "  # Recorta y escala la imagen \n",
        "  img = crop_center(img)\n",
        "  img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
        "  \n",
        "  return img\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR01aUgvvajv"
      },
      "source": [
        "Vamos ahora a cargar unas imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "S9pedlwqvdPL",
        "outputId": "9c018857-b792-4bf5-b5bb-595300d847c4"
      },
      "outputs": [],
      "source": [
        "content_image_url = 'https://proyectopuente.com.mx/wp-content/uploads/2021/03/Unison-2.jpg'\n",
        "#style_image_url = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTvjSkzPQVNjS5XOWmOwTdOdY_PaXB4T9KNW0cJIw3LIsL0zCZuhApTOfu7D0yD8dj_PhI&usqp=CAU'  \n",
        "style_image_url = 'https://media.admagazine.com/photos/618a6b39b67f79aa891edc46/master/w_1600%2Cc_limit/63307.jpg'\n",
        "output_image_size = 384 \n",
        "\n",
        "# La imagen con el contenido, puede ser de un tamaño arbitrario.\n",
        "content_img_size = (output_image_size, output_image_size)\n",
        "\n",
        "# La imagen con el estilo. Puede ser de cualquier tamaño pero el modelo que vamos a usar\n",
        "# está optimizado para imagenes de 256 x 256\n",
        "style_img_size = (256, 256)  # Recomendado mantener en 256.\n",
        "\n",
        "content_image = load_image(content_image_url, content_img_size)\n",
        "style_image = load_image(style_image_url, style_img_size)\n",
        "style_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME')\n",
        "show_n([content_image, style_image], ['Content image', 'Style image'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeIxYZlAymCO"
      },
      "source": [
        "Y ahora vamos a cargar el modelo preentrenado, el cual podemos revisar en la [página de TensorFlow Hub de este modelo](https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14GxuDIDy-dN"
      },
      "outputs": [],
      "source": [
        "hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
        "hub_module = hub.load(hub_handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAOtTdBvzr8Y"
      },
      "source": [
        "Y simplemente lo ejecutamos y vemos el resultado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch6HLfpUzvFf"
      },
      "outputs": [],
      "source": [
        "# Stylize content image with given style image.\n",
        "# This is pretty fast within a few milliseconds on a GPU.\n",
        "\n",
        "outputs = hub_module(\n",
        "    tf.constant(content_image), \n",
        "    tf.constant(style_image)\n",
        ")\n",
        "stylized_image = outputs[0]\n",
        "\n",
        "# Visualize input images and the generated stylized image.\n",
        "\n",
        "show_n(\n",
        "    [content_image, style_image, stylized_image], \n",
        "    titles=['Original content image', 'Style image', 'Stylized image']\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "transfer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
