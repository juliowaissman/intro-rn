{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR-F7ExGqaXc"
      },
      "source": [
        "<h1><b>Introducción a Tensorflow</b> </h1>\n",
        "\n",
        "<author>Julio Waissman Vilanova</author>\n",
        "\n",
        "<br/>\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/juliowaissman/intro-rn/blob/main/tf-intro.ipynb\">\n",
        "<img src=\"https://i.ibb.co/2P3SLwK/colab.png\" width=30pt />\n",
        "<i>Para usar en Google Colab</i></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_xclKym03XT"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "TensorFlow es una biblioteca de software ampliamente utilizada en aprendizaje automático. Aquí aprenderemos cómo se representan los cálculos. TensorFlow 2 ofrece una gran flexibilidad y la capacidad de ejecutar operaciones de manera imperativa. Notarás que TensorFlow 2 es bastante similar a Python en su sintaxis y ejecución imperativa. Instalemos TensorFlow y un par de dependencias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h9K2xV28qZJJ"
      },
      "outputs": [],
      "source": [
        "# Librerías clásicas de python para manejo\n",
        "# de vectores y matrices, y de graficación\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tesorflow\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki0kU_SG1xCi"
      },
      "source": [
        "TensorFlow se llama así porque maneja el flujo (nodo/operación matemática) de tensores, que son estructuras de datos que se pueden considerar como matrices multidimensionales. Los tensores se representan como matrices de n dimensiones de tipos de datos básicos, como una cadena o un número entero; proporcionan una forma de generalizar vectores y matrices a dimensiones superiores.\n",
        "\n",
        "La *forma* (`shape`) de un Tensor define su número de dimensiones y el tamaño de cada dimensión. El *rango* (`rank`) de un tensor proporciona el número de dimensiones; también puedes considerarlo como el orden o grado del tensor.\n",
        "\n",
        "Veamos primero los tensores 0-d, de los cuales un escalar es un ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7CsITAg2cf-"
      },
      "outputs": [],
      "source": [
        "deporte = tf.constant(\"Tennis\", tf.string)\n",
        "numero = tf.constant(1.41421356237, tf.float64)\n",
        "\n",
        "print(f\"`deporte` es un tensor de rango {tf.rank(deporte).numpy()}\")\n",
        "print(f\"`numero` es un tensor de rango {tf.rank(numero).numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVtGWBqZ3Aa9"
      },
      "source": [
        "Y veamos ahora unos de 1 dimensión (vectores):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7GL1XBU3Fj1"
      },
      "outputs": [],
      "source": [
        "sports = tf.constant([\"Tennis\", \"Basketball\"], tf.string)\n",
        "numbers = tf.constant([3.141592, 1.414213, 2.71821], tf.float64)\n",
        "\n",
        "print(f\"`sports` es un tensor de {tf.rank(sports).numpy()} dimensiones con forma: {tf.shape(sports)}\")\n",
        "print(f\"`numbers` es un tensor de {tf.rank(numbers).numpy()} dimensiones con forma {tf.shape(numbers)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMgdp0Xo4N1B"
      },
      "source": [
        "A continuación, consideramos la creación de tensores bidimensionales (es decir, matrices) y de rango superior. Por ejemplo, en visión por computadora se suele utilizar tensores 4-d. Aquí las dimensiones corresponden a la cantidad de imágenes de ejemplo en nuestro lote, la altura de la imagen, el ancho de la imagen y la cantidad de canales de color."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HPb2oDLf4X1j"
      },
      "outputs": [],
      "source": [
        "'''TODO: Define un tensor 2-d (Matriz)'''\n",
        "matrix = # TODO\n",
        "\n",
        "assert isinstance(matrix, tf.Tensor), \"matrix debe ser un objeto tensorflow.Tensor\"\n",
        "assert tf.rank(matrix).numpy() == 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbM2kVv042xW"
      },
      "outputs": [],
      "source": [
        "'''TODO: Define un tensor 4-d'''\n",
        "# Usa tf.zeros para inicializar un Tensor de ceros de tamaño 10 x 256 x 256 x 3.\n",
        "# Puedes pensar que es una pila de 10 imágenes a color (RGB) de 256 x 256 pixeles\n",
        "images = # TODO\n",
        "\n",
        "assert isinstance(images, tf.Tensor), \"images debe ser un objeto tensorflow.Tensor\"\n",
        "assert tf.rank(images).numpy() == 4, \"images debe de ser de rango 4\"\n",
        "assert tf.shape(images).numpy().tolist() == [10, 256, 256, 3], \"images tiene la forma incorrecta\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsYxMLP_55na"
      },
      "source": [
        "Puedes usar *slicing* para acceder a subtensores de un tensor de rango más alto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEJAADOw5ZeR"
      },
      "outputs": [],
      "source": [
        "row_vector = matrix[1]\n",
        "column_vector = matrix[:,1]\n",
        "scalar = matrix[0, 1]\n",
        "\n",
        "print(f\"row_vector: {row_vector.numpy()}\")\n",
        "print(f\"column_vector: {column_vector.numpy()}\")\n",
        "print(f\"scalar: {scalar.numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wP6x_3K6iS3"
      },
      "source": [
        "## Calculo de tensores\n",
        "\n",
        "Una forma conveniente de pensar y visualizar cálculos en TensorFlow es en términos de gráficas. Podemos definir esta gráfica en términos de tensores, que contienen datos, y las operaciones matemáticas que actúan sobre estos tensores en algún orden. Veamos un ejemplo simple y definamos este cálculo usando TensorFlow:\n",
        "\n",
        "![](https://raw.githubusercontent.com/aamini/introtodeeplearning/master/lab1/img/add-graph.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hjz8pGm67Mv"
      },
      "outputs": [],
      "source": [
        "# Crea los nódo en el grafo e inicializa los valores\n",
        "a = tf.constant(15)\n",
        "b = tf.constant(61)\n",
        "\n",
        "# Suma\n",
        "c1 = tf.add(a,b)\n",
        "c2 = a + b # \"Sobrecarga\" en TensorFlow\n",
        "print(c1)\n",
        "print(c2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I60CCWDD-5H_"
      },
      "source": [
        "Observa cómo hemos creado un gráfica de cálculo que consta de operaciones de TensorFlow ya cómo la salida es un tensor con valor 76; acabamos de crear una gráfica de cálculo que consta de operaciones, las ejecutó y nos devolvió el resultado.\n",
        "\n",
        "Ahora consideremos un ejemplo un poco más complicado:\n",
        "\n",
        "![texto alternativo](https://raw.githubusercontent.com/aamini/introtodeeplearning/master/lab1/img/computation-graph.png)\n",
        "\n",
        "Aquí, tomamos dos entradas, `a`, `b`, y calculamos una salida `e`. Cada nodo en la gráfica representa una operación que toma alguna entrada, realiza algún cálculo y pasa su salida a otro nodo.\n",
        "\n",
        "Definamos una función simple en TensorFlow para construir esta función de cálculo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgmO8_gF_s11"
      },
      "outputs": [],
      "source": [
        "### Definiendo una gráfica de operaciones en tensorflow ###\n",
        "\n",
        "def func(a,b):\n",
        "  '''\n",
        "  TODO: Define las operaciones para c, d, e\n",
        "  (usa tf.add, tf.subtract, tf.multiply).\n",
        "  '''\n",
        "  c = # TODO\n",
        "  d = # TODO\n",
        "  e = # TODO\n",
        "  return e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkygYetf__A9"
      },
      "source": [
        "Ahora, podemos llamar a esta función para ejecutar el gráfico de cálculo dadas algunas entradas `a`, `b`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO3lioZZAI8s"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de entradas para a y b\n",
        "a, b = 1.5, 2.5\n",
        "\n",
        "# Ejecuta el calculo\n",
        "e_out = func(a,b)\n",
        "\n",
        "print(e_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWu2YdKwAd4v"
      },
      "source": [
        "Observa cómo la salida es un tensor con un valor definido por el cálculo, y que la salida no tiene forma ya que es un valor escalar único."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o0HPF4FAnul"
      },
      "source": [
        "## Diferenciación automática\n",
        "\n",
        "La [Diferenciación automática](https://en.wikipedia.org/wiki/Automatic_differentiation) es una de las partes más importantes de TensorFlow y es la columna vertebral del entrenamiento con\n",
        "[b-prop](https://en.wikipedia.org/wiki/Backpropagation). Usaremos [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape?version=stable) para registrar operaciones y calcular gradientes más adelante.\n",
        "\n",
        "Cuando se calcular nlos valores de una gráfica de operaciones en TensorFlow, todas las operaciones de paso hacia adelante se graban en una *cinta*. Luego, para calcular el gradiente, la cinta se reproduce al revés. De forma predeterminada, la cinta se descarta después de reproducirla al revés; esto significa que un `tf.GradientTape` particular solo puede calcula un gradiente y las llamadas posteriores arrojan un error de tiempo de ejecución. Sin embargo, podemos calcular múltiples gradientes en el mismo cálculo creando una cinta de gradiente ```persistente```.\n",
        "\n",
        "Primero, veremos cómo podemos calcular gradientes usando `tf.GradientTape` y acceder a ellos para realizar el cálculo. Definimos la función simple $ z = x^4$ pero usando dos funciones: $z = y^2$ y $y = x^2$ y calculamos el gradiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TtXYnqrQBOm6"
      },
      "outputs": [],
      "source": [
        "### Cálculo de gradientes con GradientTape ###\n",
        "\n",
        "# z = y^2\n",
        "# y = x^2\n",
        "# dz_dx = 4 * x^3\n",
        "\n",
        "# Ejemplo: x = 3.0\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "# Inicializa la cinta\n",
        "with tf.GradientTape() as tape:\n",
        "  # Define la función\n",
        "  y = x * x\n",
        "  z = y * y\n",
        "# Accesa la cita y encuentra la derivada de y respecto a x\n",
        "dy_dx = tape.gradient(z, x)\n",
        "\n",
        "assert dy_dx.numpy() == 4 * x.value()**3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKkCSE8zDMSw"
      },
      "source": [
        "Al entrenar redes neuronales, utilizamos diferenciación y descenso de gradiente estocástico (SGD) para optimizar una función de pérdida.\n",
        "\n",
        "Ahora que tenemos una idea de cómo se puede usar `GradientTape` para calcular y acceder a derivadas, veremos un ejemplo en el que usamos diferenciación automática y SGD para encontrar el mínimo de $loss=(x-x_f)^2$.\n",
        "\n",
        "Aquí $x_f$ es una variable para un valor deseado que estamos tratando de optimizar; $L$ representa una pérdida que estamos tratando de minimizar. Si bien podemos resolver claramente este problema analíticamente ($x_{min}=x_f$), considerar cómo podemos calcular esto usando `GradientTape` nos ayuda a entender como funcionan las redes neuronales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpsMmzLmGPBt"
      },
      "source": [
        "## Taller\n",
        "\n",
        "**Realiza correctamente el método y grafica en la celda de abajo.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WzSBPBe1DoFF"
      },
      "outputs": [],
      "source": [
        "### Usando gradiente estocástico para  ###\n",
        "\n",
        "# Inicializa el valor inicial de x en forma aleatoria\n",
        "x = tf.Variable([tf.random.normal([1])])\n",
        "\n",
        "# El valor final esperado\n",
        "x_f = tf.constant(4.0)\n",
        "\n",
        "# Parámetros de SGD\n",
        "EPOCHS = 500 # Número de iteraciones\n",
        "lr = 1e-2 # Tasa de aprendizaje\n",
        "history = []\n",
        "\n",
        "for _ in range(EPOCHS):\n",
        "  with tf.GradientTape() as tape:\n",
        "    '''TODO: define la función de pérdida a optimizar'''\n",
        "    loss = # TODO\n",
        "\n",
        "  # Obteniendo el gradiente\n",
        "  grad = tape.gradient(loss, x)\n",
        "\n",
        "  # Aplicando el decenso de gradiente\n",
        "  new_x = x - lr * grad\n",
        "\n",
        "  # Asignando el nuevo valor de x\n",
        "  x.assign(new_x)\n",
        "\n",
        "  # Agregando el valor al historial\n",
        "  history.append(x.numpy()[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqdMNwxIFFOM"
      },
      "outputs": [],
      "source": [
        "# Plot the evolution of x as we optimize towards x_f!\n",
        "plt.plot(history)\n",
        "plt.plot([0, 500],[x_f,x_f])\n",
        "plt.legend(('Predicha', 'Esperada'))\n",
        "plt.xlabel('Iteración (epoch)')\n",
        "plt.ylabel('Valor de x')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
